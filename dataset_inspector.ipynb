{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset paths configured.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "# Dataset paths\n",
    "DATASET_DIR = Path(\"resource/dataset\")\n",
    "SA_SGG_PATH = DATASET_DIR / \"generation\" / \"sa-sgg.jsonl\"\n",
    "MA_SGG_PATH = DATASET_DIR / \"generation\" / \"ma-sgg.jsonl\"\n",
    "SGQA_PATH = DATASET_DIR / \"understanding\" / \"sgqa.jsonl\"\n",
    "SGDS_PATH = DATASET_DIR / \"understanding\" / \"sgds.jsonl\"\n",
    "\n",
    "print(\"Dataset paths configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Helper Functions\n",
    "\n",
    "def load_jsonl(path):\n",
    "    \"\"\"Load a JSONL file into a list of dictionaries.\"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "def sample_data(data, n=1, seed=None):\n",
    "    \"\"\"Randomly sample n items from data.\"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    return random.sample(data, min(n, len(data)))\n",
    "\n",
    "def display_sample(sample, title=\"Sample\"):\n",
    "    \"\"\"Pretty print a sample with a title.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{title}\")\n",
    "    print('='*80)\n",
    "    pprint(sample, width=100, depth=4)\n",
    "\n",
    "print(\"Helper functions loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA-SGG Dataset Statistics:\n",
      "  Total samples: 1188\n",
      "  Fields: ['data_id', 'doc_index', 'text_part_index', 'context', 'target_sentence', 'graph_id', 'is_repeatable', 'graphs', 'verbs', 'mandatory_space', 'context_graphs']\n",
      "\n",
      "================================================================================\n",
      "RANDOM SA-SGG SAMPLE\n",
      "================================================================================\n",
      "\n",
      "[Target Sentence]\n",
      "  Finally, the bike was let go, marking the end of the maintenance session.\n",
      "\n",
      "[Context]\n",
      "  The bundle was picked up and securely grasped. Using the other hand, the bundle was opened to reveal its contents. Finally, the bundle was laid down carefully. The process began by picking up the screwdriver. With precision, the fastener on the instrument was secured using the screwdriver. Once the ...\n",
      "\n",
      "[Ground Truth Scene Graph(s)]\n",
      "  Graph 1 (action_id: -2):\n",
      "    person -> verb -> release\n",
      "    release -> dobj -> motorcycle\n",
      "    release -> from -> hand1\n",
      "    release -> from -> hand2\n",
      "\n",
      "[Mandatory Space (allowed vocabulary)]\n",
      "  Verbs: ['adjust', 'carry', 'check', 'clean', 'close', 'examine', 'fix', 'hit']...\n",
      "  Objects: ['person', 'carton', 'drawer', 'gauge', 'hammer', 'hand1', 'hand2', 'metal']...\n",
      "  Relationships: ['dobj', 'from', 'into', 'on', 'verb', 'with']\n"
     ]
    }
   ],
   "source": [
    "# Load SA-SGG dataset\n",
    "sa_sgg_data = load_jsonl(SA_SGG_PATH)\n",
    "\n",
    "print(f\"SA-SGG Dataset Statistics:\")\n",
    "print(f\"  Total samples: {len(sa_sgg_data)}\")\n",
    "print(f\"  Fields: {list(sa_sgg_data[0].keys())}\")\n",
    "\n",
    "# Sample and display\n",
    "sample = sample_data(sa_sgg_data, n=1)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANDOM SA-SGG SAMPLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n[Target Sentence]\")\n",
    "print(f\"  {sample['target_sentence']}\")\n",
    "\n",
    "print(f\"\\n[Context]\")\n",
    "print(f\"  {sample['context'][:300]}...\" if len(sample.get('context', '')) > 300 else f\"  {sample.get('context', '(none)')}\")\n",
    "\n",
    "print(f\"\\n[Ground Truth Scene Graph(s)]\")\n",
    "for i, graph in enumerate(sample['graphs']):\n",
    "    print(f\"  Graph {i+1} (action_id: {graph['action_id']}):\")\n",
    "    for triplet in graph['triplets']:\n",
    "        print(f\"    {triplet[0]} -> {triplet[1]} -> {triplet[2]}\")\n",
    "\n",
    "print(f\"\\n[Mandatory Space (allowed vocabulary)]\")\n",
    "print(f\"  Verbs: {sample['mandatory_space']['verb'][:8]}...\")\n",
    "print(f\"  Objects: {sample['mandatory_space']['object'][:8]}...\")\n",
    "print(f\"  Relationships: {sample['mandatory_space']['relationship']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA-SGG Dataset Statistics:\n",
      "  Total samples: 853\n",
      "  Fields: ['data_id', 'doc_index', 'text_part_index', 'context', 'target_sentence', 'graph_id', 'is_repeatable', 'graphs', 'verbs', 'mandatory_space', 'context_graphs']\n",
      "\n",
      "================================================================================\n",
      "RANDOM MA-SGG SAMPLE (with multiple actions)\n",
      "================================================================================\n",
      "\n",
      "[Target Sentence]\n",
      "  Once cooked, the dough strips were transferred to a dish.\n",
      "\n",
      "[Number of Actions]: 2\n",
      "\n",
      "[Ground Truth Scene Graphs]\n",
      "\n",
      "  Scene Graph 1 (action_id: 22):\n",
      "    remove -> with -> hand1\n",
      "    remove -> dobj -> cooked-dough-strips\n",
      "    remove -> with -> spatula\n",
      "    person -> verb -> remove\n",
      "\n",
      "  Scene Graph 2 (action_id: 23):\n",
      "    place -> with -> hand1\n",
      "    place -> dobj -> cooked-dough-strips\n",
      "    place -> on -> plate\n",
      "    person -> verb -> place\n"
     ]
    }
   ],
   "source": [
    "# Load MA-SGG dataset\n",
    "ma_sgg_data = load_jsonl(MA_SGG_PATH)\n",
    "\n",
    "print(f\"MA-SGG Dataset Statistics:\")\n",
    "print(f\"  Total samples: {len(ma_sgg_data)}\")\n",
    "print(f\"  Fields: {list(ma_sgg_data[0].keys())}\")\n",
    "\n",
    "# Find a sample with multiple graphs\n",
    "multi_graph_samples = [s for s in ma_sgg_data if len(s['graphs']) > 1]\n",
    "sample = sample_data(multi_graph_samples, n=1)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANDOM MA-SGG SAMPLE (with multiple actions)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n[Target Sentence]\")\n",
    "print(f\"  {sample['target_sentence']}\")\n",
    "\n",
    "print(f\"\\n[Number of Actions]: {len(sample['graphs'])}\")\n",
    "\n",
    "print(f\"\\n[Ground Truth Scene Graphs]\")\n",
    "for i, graph in enumerate(sample['graphs']):\n",
    "    print(f\"\\n  Scene Graph {i+1} (action_id: {graph['action_id']}):\")\n",
    "    for triplet in graph['triplets']:\n",
    "        print(f\"    {triplet[0]} -> {triplet[1]} -> {triplet[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGQA Dataset Statistics:\n",
      "  Total samples: 100\n",
      "  Total QA pairs: 500\n",
      "  Avg QA pairs per sample: 5.0\n",
      "  Fields: ['data_id', 'doc_index', 'text_part_index', 'context_graphs', 'qa_pairs']\n",
      "\n",
      "================================================================================\n",
      "RANDOM SGQA SAMPLE\n",
      "================================================================================\n",
      "\n",
      "[Context Graphs] (27 scene graphs)\n",
      "\n",
      "  Graph 1:\n",
      "    adjust -> dobj -> fabric\n",
      "    adjust -> with -> hand1\n",
      "    adjust -> with -> hand2\n",
      "    person -> verb -> adjust\n",
      "\n",
      "  Graph 2:\n",
      "    fold -> dobj -> fabric\n",
      "    fold -> with -> hand1\n",
      "    fold -> with -> hand2\n",
      "    person -> verb -> fold\n",
      "\n",
      "  Graph 3:\n",
      "    pick-up -> dobj -> fabric\n",
      "    pick-up -> with -> hand1\n",
      "    pick-up -> with -> hand2\n",
      "    person -> verb -> pick-up\n",
      "\n",
      "  ... (24 more graphs)\n",
      "\n",
      "[Question-Answer Pairs] (5 pairs)\n",
      "\n",
      "  Q1: What object was repeatedly adjusted before the first ironing action occurred?\n",
      "  A1: fabric\n",
      "\n",
      "  Q2: Which tool was consistently used for single-handed pick-up actions throughout the sequence?\n",
      "  A2: hand1\n",
      "\n",
      "  Q3: What object was placed on the ironing-board immediately after the first folding action?\n",
      "  A3: fabric\n",
      "\n",
      "  Q4: Which object was manipulated with both hands before being moved to the final destination?\n",
      "  A4: fabric\n",
      "\n",
      "  Q5: What was the last surface-type object that the fabric interacted with in the sequence?\n",
      "  A5: table\n"
     ]
    }
   ],
   "source": [
    "# Load SGQA dataset\n",
    "sgqa_data = load_jsonl(SGQA_PATH)\n",
    "\n",
    "total_qa_pairs = sum(len(s['qa_pairs']) for s in sgqa_data)\n",
    "\n",
    "print(f\"SGQA Dataset Statistics:\")\n",
    "print(f\"  Total samples: {len(sgqa_data)}\")\n",
    "print(f\"  Total QA pairs: {total_qa_pairs}\")\n",
    "print(f\"  Avg QA pairs per sample: {total_qa_pairs / len(sgqa_data):.1f}\")\n",
    "print(f\"  Fields: {list(sgqa_data[0].keys())}\")\n",
    "\n",
    "# Sample and display\n",
    "sample = sample_data(sgqa_data, n=1)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANDOM SGQA SAMPLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n[Context Graphs] ({len(sample['context_graphs'])} scene graphs)\")\n",
    "for i, graph in enumerate(sample['context_graphs'][:3]):  # Show first 3\n",
    "    print(f\"\\n  Graph {i+1}:\")\n",
    "    for triplet in graph[:4]:  # Show first 4 triplets\n",
    "        print(f\"    {triplet[0]} -> {triplet[1]} -> {triplet[2]}\")\n",
    "    if len(graph) > 4:\n",
    "        print(f\"    ... ({len(graph) - 4} more triplets)\")\n",
    "if len(sample['context_graphs']) > 3:\n",
    "    print(f\"\\n  ... ({len(sample['context_graphs']) - 3} more graphs)\")\n",
    "\n",
    "print(f\"\\n[Question-Answer Pairs] ({len(sample['qa_pairs'])} pairs)\")\n",
    "for i, qa in enumerate(sample['qa_pairs']):\n",
    "    print(f\"\\n  Q{i+1}: {qa['Q']}\")\n",
    "    print(f\"  A{i+1}: {qa['A']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDS Dataset Statistics:\n",
      "  Total samples: 250\n",
      "  Fields: ['target_sentence', 'position', 'variations', 'triplet', 'context_graphs']\n",
      "\n",
      "================================================================================\n",
      "RANDOM SGDS SAMPLE\n",
      "================================================================================\n",
      "\n",
      "[Scene Graph Triplets]\n",
      "  person -> verb -> pour\n",
      "  pour -> dobj -> water\n",
      "  pour -> from -> cup\n",
      "  pour -> into -> keg\n",
      "  pour -> with -> hand1\n",
      "\n",
      "[Candidate Descriptions]\n",
      "  [A] Once secured, the fastener was let go.\n",
      "  [B] The crochet hook was then picked up again.\n",
      "  [C] Finally, the plant was modified with one hand to achieve the perfect alignment within the container.\n",
      "  [D] Finally, the water was transferred from the mug into the barrel, ensuring it was ready for use. <-- CORRECT\n",
      "  [E] Finally, the paint can was put down carefully.\n",
      "\n",
      "[Correct Answer]: D (position 3)\n"
     ]
    }
   ],
   "source": [
    "# Load SGDS dataset\n",
    "sgds_data = load_jsonl(SGDS_PATH)\n",
    "\n",
    "print(f\"SGDS Dataset Statistics:\")\n",
    "print(f\"  Total samples: {len(sgds_data)}\")\n",
    "print(f\"  Fields: {list(sgds_data[0].keys())}\")\n",
    "\n",
    "# Sample and display\n",
    "sample = sample_data(sgds_data, n=1)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANDOM SGDS SAMPLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n[Scene Graph Triplets]\")\n",
    "for triplet in sample['triplet']:\n",
    "    print(f\"  {triplet[0]} -> {triplet[1]} -> {triplet[2]}\")\n",
    "\n",
    "print(f\"\\n[Candidate Descriptions]\")\n",
    "for i, desc in enumerate(sample['variations']):\n",
    "    marker = \" <-- CORRECT\" if i == sample['position'] else \"\"\n",
    "    print(f\"  [{chr(65+i)}] {desc}{marker}\")\n",
    "\n",
    "print(f\"\\n[Correct Answer]: {chr(65 + sample['position'])} (position {sample['position']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSG-Bench Dataset Summary\n",
      "================================================================================\n",
      "  Task          Type  Samples                          Description\n",
      "SA-SGG    Generation     1188 Single-Action Scene Graph Generation\n",
      "MA-SGG    Generation      853  Multi-Action Scene Graph Generation\n",
      "  SGQA Understanding      100        Scene Graph QA (500 QA pairs)\n",
      "  SGDS Understanding      250    Scene Graph Description Selection\n",
      "\n",
      "Total samples: 2391\n"
     ]
    }
   ],
   "source": [
    "# Summary table\n",
    "total_qa = sum(len(s['qa_pairs']) for s in sgqa_data)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Task': ['SA-SGG', 'MA-SGG', 'SGQA', 'SGDS'],\n",
    "    'Type': ['Generation', 'Generation', 'Understanding', 'Understanding'],\n",
    "    'Samples': [len(sa_sgg_data), len(ma_sgg_data), len(sgqa_data), len(sgds_data)],\n",
    "    'Description': [\n",
    "        'Single-Action Scene Graph Generation',\n",
    "        'Multi-Action Scene Graph Generation', \n",
    "        f'Scene Graph QA ({total_qa} QA pairs)',\n",
    "        'Scene Graph Description Selection'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"TSG-Bench Dataset Summary\")\n",
    "print(\"=\"*80)\n",
    "print(summary.to_string(index=False))\n",
    "print(f\"\\nTotal samples: {summary['Samples'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsg-bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
