None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
Loading SGQA Hard Benchmark...
Loaded 88 hard cases
Using QA model: GPT5Mini
Using gen model: GPT5Mini

Building background dataset from all SGQA actions...
Background dataset: 2546 action graphs

Generating EpiMine episode hierarchies...

Generating EpiMine episode hierarchies for 55 samples...
[1/55] Processing 860980fb-f992-4bb1-8...[2/55] Processing 41b8254c-ca1e-464c-9...[3/55] Processing 312da1d0-9e56-4f5e-b...[4/55] Processing 3db79f36-a611-42f6-b...[5/55] Processing 3ea57fa2-fd76-48c1-9...[6/55] Processing 82dc7a9e-a0a4-4611-8...[7/55] Processing a0d6bd8e-c477-442b-b...[8/55] Processing f643d88a-92cc-456d-b...[9/55] Processing 1695475c-e527-43e6-b...[10/55] Processing 44ae604b-2e16-497d-a...[11/55] Processing 49374bc5-0999-49dc-8...[12/55] Processing 6f082d5d-5f31-4358-b...[13/55] Processing 950f70a4-f90b-4a15-9...[14/55] Processing d19faa97-b823-4c1d-b...[15/55] Processing d4fc1fd7-c725-454e-9...[16/55] Processing d6de6eee-b844-49c9-8...[17/55] Processing e08c9103-d6a0-4a43-8...[18/55] Processing e43f5b38-213a-4d42-a...[19/55] Processing e8cf9894-0cc7-4480-b...[20/55] Processing e9be1118-a5cf-4431-b...[21/55] Processing ea87324e-d129-425f-b...[22/55] Processing efa59c4e-71de-4184-9...[23/55] Processing f646012d-baca-46a6-b...[24/55] Processing fbf4150a-27d2-48a4-9...[25/55] Processing fdb68b7b-f09f-4a71-a...[26/55] Processing 7070897e-556f-421a-b...[27/55] Processing 203ee455-6f60-4e08-b...[28/55] Processing 5533ab65-7463-47a6-b...[29/55] Processing 954c2f61-64ad-4c89-a...[30/55] Processing a814274f-898a-4bc4-a...[31/55] Processing c7cc9fbf-e47a-4bc7-9...[32/55] Processing d851b431-8551-492b-8...[33/55] Processing df0fa70d-600e-477b-a...[34/55] Processing 1560b9ee-e2da-4dda-a...[35/55] Processing 277b18de-4ad9-4c09-9...[36/55] Processing 352f1eea-606d-4cd7-9...[37/55] Processing 577f3941-c9f6-45d3-8...[38/55] Processing 8be918b2-c819-4a84-9...[39/55] Processing ab5f1a57-29b3-4c07-b...[40/55] Processing 9f9f42f0-b9fc-4247-8...[41/55] Processing 15d4a2c1-1cb8-4b76-a...[42/55] Processing 1db339f1-f887-4e46-8...[43/55] Processing 32e25924-9d92-4030-a...[44/55] Processing 4ad40842-5cee-49c2-a...[45/55] Processing 5ec85bbd-e6c4-46e3-8...[46/55] Processing a61ec2b9-bc21-4e55-a...[47/55] Processing d84b8c76-d6b9-4e27-a...[48/55] Processing 1fdbef9f-8aa7-46b1-8...[49/55] Processing c4d332b2-7fcc-4993-b...[50/55] Processing 19ed57bf-e23d-425b-a...[51/55] Processing 2ae97f2a-b16d-467b-b...[52/55] Processing 831a2da3-bf97-4a79-a...[53/55] Processing a1f09ebf-619d-41fd-8...[54/55] Processing dabf199a-bf55-440d-8...[55/55] Processing fefb0892-7e1a-4a34-9...
Saved EpiMine episode hierarchies to: /home/jtu9/sgg/tsg-bench/anygran/hard_bench/cache/epimine_episodes_t1.5_mf2_topk10_gen5m.json
Generated 119 episodes across 55 samples (avg: 2.16)

============================================================
Running EpiMine Hierarchical Evaluation with GPT5Mini
Total cases: 88
============================================================

[EpiMine-GPT5Mini] 1/88 | EM: 0.0%[EpiMine-GPT5Mini] 2/88 | EM: 0.0%[EpiMine-GPT5Mini] 3/88 | EM: 0.0%[EpiMine-GPT5Mini] 4/88 | EM: 25.0%[EpiMine-GPT5Mini] 5/88 | EM: 20.0%[EpiMine-GPT5Mini] 6/88 | EM: 16.7%[EpiMine-GPT5Mini] 7/88 | EM: 14.3%[EpiMine-GPT5Mini] 8/88 | EM: 12.5%[EpiMine-GPT5Mini] 9/88 | EM: 11.1%[EpiMine-GPT5Mini] 10/88 | EM: 10.0%[EpiMine-GPT5Mini] 11/88 | EM: 9.1%[EpiMine-GPT5Mini] 12/88 | EM: 8.3%[EpiMine-GPT5Mini] 13/88 | EM: 7.7%[EpiMine-GPT5Mini] 14/88 | EM: 7.1%[EpiMine-GPT5Mini] 15/88 | EM: 6.7%[EpiMine-GPT5Mini] 16/88 | EM: 6.2%[EpiMine-GPT5Mini] 17/88 | EM: 5.9%[EpiMine-GPT5Mini] 18/88 | EM: 5.6%[EpiMine-GPT5Mini] 19/88 | EM: 5.3%[EpiMine-GPT5Mini] 20/88 | EM: 5.0%[EpiMine-GPT5Mini] 21/88 | EM: 4.8%[EpiMine-GPT5Mini] 22/88 | EM: 4.5%[EpiMine-GPT5Mini] 23/88 | EM: 4.3%[EpiMine-GPT5Mini] 24/88 | EM: 4.2%[EpiMine-GPT5Mini] 25/88 | EM: 4.0%[EpiMine-GPT5Mini] 26/88 | EM: 3.8%[EpiMine-GPT5Mini] 27/88 | EM: 3.7%[EpiMine-GPT5Mini] 28/88 | EM: 3.6%[EpiMine-GPT5Mini] 29/88 | EM: 3.4%[EpiMine-GPT5Mini] 30/88 | EM: 3.3%[EpiMine-GPT5Mini] 31/88 | EM: 3.2%[EpiMine-GPT5Mini] 32/88 | EM: 3.1%[EpiMine-GPT5Mini] 33/88 | EM: 3.0%[EpiMine-GPT5Mini] 34/88 | EM: 5.9%[EpiMine-GPT5Mini] 35/88 | EM: 5.7%[EpiMine-GPT5Mini] 36/88 | EM: 5.6%[EpiMine-GPT5Mini] 37/88 | EM: 5.4%[EpiMine-GPT5Mini] 38/88 | EM: 5.3%[EpiMine-GPT5Mini] 39/88 | EM: 7.7%[EpiMine-GPT5Mini] 40/88 | EM: 10.0%[EpiMine-GPT5Mini] 41/88 | EM: 12.2%[EpiMine-GPT5Mini] 42/88 | EM: 14.3%[EpiMine-GPT5Mini] 43/88 | EM: 14.0%[EpiMine-GPT5Mini] 44/88 | EM: 15.9%[EpiMine-GPT5Mini] 45/88 | EM: 15.6%[EpiMine-GPT5Mini] 46/88 | EM: 15.2%[EpiMine-GPT5Mini] 47/88 | EM: 17.0%[EpiMine-GPT5Mini] 48/88 | EM: 18.8%[EpiMine-GPT5Mini] 49/88 | EM: 20.4%[EpiMine-GPT5Mini] 50/88 | EM: 22.0%[EpiMine-GPT5Mini] 51/88 | EM: 23.5%[EpiMine-GPT5Mini] 52/88 | EM: 23.1%[EpiMine-GPT5Mini] 53/88 | EM: 22.6%[EpiMine-GPT5Mini] 54/88 | EM: 22.2%[EpiMine-GPT5Mini] 55/88 | EM: 23.6%[EpiMine-GPT5Mini] 56/88 | EM: 23.2%[EpiMine-GPT5Mini] 57/88 | EM: 24.6%[EpiMine-GPT5Mini] 58/88 | EM: 24.1%[EpiMine-GPT5Mini] 59/88 | EM: 25.4%[EpiMine-GPT5Mini] 60/88 | EM: 25.0%[EpiMine-GPT5Mini] 61/88 | EM: 26.2%[EpiMine-GPT5Mini] 62/88 | EM: 25.8%[EpiMine-GPT5Mini] 63/88 | EM: 25.4%[EpiMine-GPT5Mini] 64/88 | EM: 26.6%[EpiMine-GPT5Mini] 65/88 | EM: 27.7%[EpiMine-GPT5Mini] 66/88 | EM: 27.3%[EpiMine-GPT5Mini] 67/88 | EM: 28.4%[EpiMine-GPT5Mini] 68/88 | EM: 27.9%[EpiMine-GPT5Mini] 69/88 | EM: 29.0%[EpiMine-GPT5Mini] 70/88 | EM: 30.0%[EpiMine-GPT5Mini] 71/88 | EM: 31.0%[EpiMine-GPT5Mini] 72/88 | EM: 30.6%[EpiMine-GPT5Mini] 73/88 | EM: 31.5%[EpiMine-GPT5Mini] 74/88 | EM: 31.1%[EpiMine-GPT5Mini] 75/88 | EM: 30.7%[EpiMine-GPT5Mini] 76/88 | EM: 30.3%[EpiMine-GPT5Mini] 77/88 | EM: 31.2%[EpiMine-GPT5Mini] 78/88 | EM: 30.8%[EpiMine-GPT5Mini] 79/88 | EM: 31.6%[EpiMine-GPT5Mini] 80/88 | EM: 32.5%[EpiMine-GPT5Mini] 81/88 | EM: 32.1%[EpiMine-GPT5Mini] 82/88 | EM: 32.9%[EpiMine-GPT5Mini] 83/88 | EM: 33.7%[EpiMine-GPT5Mini] 84/88 | EM: 34.5%[EpiMine-GPT5Mini] 85/88 | EM: 35.3%[EpiMine-GPT5Mini] 86/88 | EM: 36.0%[EpiMine-GPT5Mini] 87/88 | EM: 35.6%[EpiMine-GPT5Mini] 88/88 | EM: 36.4%
Saved results to: /home/jtu9/sgg/tsg-bench/anygran/hard_bench/results/hard_epimine_gpt5-mini_t1.5_mf2_topk10_llm1_gen5m.json

============================================================
EPIMINE SGQA-HARD RESULTS
============================================================
Model:     EpiMine-GPT5Mini
Total:     88
Correct:   32
Accuracy:  36.36%
============================================================
